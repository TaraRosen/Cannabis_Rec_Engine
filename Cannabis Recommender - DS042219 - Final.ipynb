{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting options to display entire dataframes\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to scrape the www.leafly.com/explore/sort-alpha page to build \n",
    "the urls for each strain's webpage on leafly.com. After some exploration,\n",
    "I discovered that www.leafly.com/explore/sort-alpha was masking its \n",
    "page numbers. Realizing this made it easier to build all of the \n",
    "strain's urls.\n",
    "\n",
    "1) Scrape for strain names and build url df - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick look at https://www.leafly.com/explore/page-61/sort-alpha shows \n",
    "#that page-61 is the last page of strains\n",
    "\n",
    "pages = 61 \n",
    "strain_names = []\n",
    "websites = []\n",
    "\n",
    "for i in range(pages+1):\n",
    "    page_url = \"https://www.leafly.com/explore/page-\"+str(i)+\"/sort-alpha\"\n",
    "    html = requests.get(page_url).text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    urls = soup.findAll(\"a\",{\"class\":\"ga_Explore_Strain_Tile\"})\n",
    "        \n",
    "    for url in urls:\n",
    "        strain_name = url.get('href')\n",
    "        strain_names.append(strain_name)\n",
    "        website = (\"https://www.leafly.com\" + strain_name)\n",
    "        websites.append(website)\n",
    "\n",
    "        \n",
    "#create strain_names csv\n",
    "strains_df = pd.DataFrame(strain_names, columns = ['strain_name'])\n",
    "\n",
    "#create strain_names csv\n",
    "strains_df.to_csv('strains.csv')\n",
    "        \n",
    "#create url df\n",
    "url_df = pd.DataFrame(websites, columns = ['url'])\n",
    "\n",
    "#create url csv\n",
    "url_df.to_csv('urls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to start to build out a master dataframe with the strain name,\n",
    "type, attributes and flavors. Here I start to with extracting the \n",
    "strain name and strain type from the html scrape. I frequently saved \n",
    "my dataframes to csvs since there is always a chance of losing \n",
    "your data and I did not want to have to repeatedly scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse strain_name:\n",
    "parsed =[]\n",
    "for words in strains_df['strain_name']:\n",
    "    parse = re.findall(r\"[\\w']+\", words)\n",
    "    parsed.append(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create name and strain type df\n",
    "strain_type_df = pd.DataFrame(parsed, columns = ['strain', 'name1', 'name2',\n",
    "                                    'name3', 'name4', 'name5', 'name6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop last 5 columns - just fillers\n",
    "strain_type_df.drop(df.tail(5).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge name columns\n",
    "strain_type_df['name'] = strain_type_df[strain_type_df.columns[1:]].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "strain_type_df.drop(['name1', 'name2', 'name3', 'name4', 'name5', 'name6'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df to csv\n",
    "strain_type_df.to_csv('strain_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of duplicates\n",
    "df['name'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['url'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Scrape each strain url - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping for html code of all of the leafly strains\n",
    "urls_total = urls_df['url']     \n",
    "\n",
    "#scrape individual strain pages\n",
    "soups_total = []\n",
    "\n",
    "for url in urls_total:\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    soups_total.append(soup)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Features From Tags\n",
    "\n",
    "In addition to the strain name and strain type, my final dataframe \n",
    "will consist of the positive effects, medical purposes, negative \n",
    "effects and flavors. I also scraped for parental lineage but did not \n",
    "end up using this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect positive effects\n",
    "\n",
    "effect = []\n",
    "filename1 = \"effect.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href') \n",
    "            strain = strain_name.split('/')\n",
    "        div = soups_total[i].find('div', {'id': 'effects-tab-content'})\n",
    "        first_child = div.findChildren('div', {'class': \"histogram-label\"})\n",
    "        try:\n",
    "            if len(first_child) == 5:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                    first_child[2].text, first_child[3].text, \n",
    "                        first_child[4].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 4:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text, first_child[3].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    effect.append(par)\n",
    "\n",
    "#create df and save to csv\n",
    "df_effect = pd.DataFrame(effect)\n",
    "df_effect.to_csv(filename1)\n",
    "\n",
    "#collect medical attributes\n",
    "\n",
    "med = []\n",
    "filename2 = \"med.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href') \n",
    "            strain = strain_name.split('/')\n",
    "        div = soups_total[i].find('div', {'id': 'medical-tab-content'})\n",
    "        first_child = div.findChildren('div', {'class': \"histogram-label\"})\n",
    "        try:\n",
    "            if len(first_child) == 5:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                    first_child[2].text, first_child[3].text, \n",
    "                        first_child[4].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 4:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text, first_child[3].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    med.append(par)\n",
    "\n",
    "#create df and save to csv\n",
    "df_med = pd.DataFrame(med)\n",
    "df_med.to_csv(filename2)\n",
    "\n",
    "#collect negative attributes\n",
    "\n",
    "neg = []\n",
    "filename3 = \"neg.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href') \n",
    "            strain = strain_name.split('/')\n",
    "        div = soups_total[i].find('div', {'id': 'negatives-tab-content'})\n",
    "        first_child = div.findChildren('div', {'class': \"histogram-label\"})\n",
    "        try:\n",
    "            if len(first_child) == 5:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                    first_child[2].text, first_child[3].text, \n",
    "                        first_child[4].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 4:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text, first_child[3].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                          first_child[2].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            \n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    neg.append(par)\n",
    "\n",
    "#create df and save to csv\n",
    "df_neg = pd.DataFrame(neg)\n",
    "df_neg.to_csv(filename3)\n",
    "\n",
    "#collect flavors\n",
    "\n",
    "flavors = []\n",
    "filename4 = \"flavors.csv\"\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    names = []\n",
    "    cont = soups_total[i].find(\"a\",{\"class\":\"active\"})  \n",
    "    names.append(cont)\n",
    "    try:\n",
    "        for name in names:\n",
    "            strain_name = name.get('href')\n",
    "            strain = strain_name.split('/')\n",
    "        first_child = soups_total[i].findAll('div',attrs={\"class\" : \"flavor-name\"})\n",
    "        try:\n",
    "            if len(first_child) == 3:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text, \n",
    "                        first_child[2].text]\n",
    "                par = {key:values}\n",
    "            elif len(first_child) == 2:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text, first_child[1].text]\n",
    "                par = {key:values}\n",
    "            elif len(first_child) == 1:\n",
    "                key = strain[2]\n",
    "                values = [first_child[0].text]\n",
    "                par = {key:values}\n",
    "            else:\n",
    "                key = strain[2]\n",
    "                values = None\n",
    "                par = {key:values}       \n",
    "        except:\n",
    "            key = strain[2]\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        key = strain[2]\n",
    "        values = None\n",
    "        par = {key:values}\n",
    "    \n",
    "        \n",
    "    flavors.append(par)\n",
    "\n",
    "#create df and save to csv\n",
    "df_flavors = pd.DataFrame(flavors)\n",
    "df_flavors.to_csv(filename4)  \n",
    "\n",
    "#collect parents of strains\n",
    "\n",
    "parents = []\n",
    "\n",
    "filename5 = 'parents.csv'\n",
    "\n",
    "for i in tqdm(range(0, len(soups_total))): \n",
    "    children = soups_total[i].findAll('div',attrs={\"class\" : \"strain-tile-footer\"})\n",
    "    try:\n",
    "        if len(children) == 3:\n",
    "            key = children[0].text\n",
    "            values = [children[1].text, children[2].text]\n",
    "            par = {key:values}\n",
    "        elif len(children) == 2:\n",
    "            key = children[0].text\n",
    "            values = children[1].text\n",
    "            par = {key:values}        \n",
    "        else:\n",
    "            key = children[0].text\n",
    "            values = None\n",
    "            par = {key:values}\n",
    "    except:\n",
    "        None\n",
    "        #print(\"can't find that page\")\n",
    "    \n",
    "    parents.append(par)\n",
    "   \n",
    "#create df and save to csv\n",
    "df_parents = pd.DataFrame(parents)\n",
    "df_parents.to_csv(filename5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Engineer Individual Dataframes\n",
    "#### Import CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import categories - hybrid, sativa, indica\n",
    "#strain_type.csv from above was renamed as \n",
    "#strain_category.csv in pages\n",
    "cat_df = pd.read_csv('strain_category.csv')\n",
    "\n",
    "#import flavors\n",
    "flav_df = pd.read_csv('flavors.csv')\n",
    "\n",
    "#import parents\n",
    "par_df = pd.read_csv('parents.csv')\n",
    "\n",
    "#import effects\n",
    "eff_df = pd.read_csv('effect.csv')\n",
    "\n",
    "#import medical\n",
    "med_df = pd.read_csv('med.csv')\n",
    "\n",
    "#import negative\n",
    "neg_df = pd.read_csv('neg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot Tables/Table Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function drop unnecessary first column\n",
    "def drop_column(df):\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first column on all dfs\n",
    "drop_column(flav_df)\n",
    "drop_column(par_df)\n",
    "drop_column(eff_df)\n",
    "drop_column(med_df)\n",
    "drop_column(neg_df)\n",
    "drop_column(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot tables so that column names (strains) are now indices\n",
    "flav_series = flav_df.stack()\n",
    "par_series = par_df.stack()\n",
    "eff_series = eff_df.stack()\n",
    "med_series = med_df.stack()\n",
    "neg_series = neg_df.stack()\n",
    "\n",
    "#convert from series to dataframe\n",
    "flav_df = flav_series.to_frame(name='flavor')\n",
    "par_df = par_series.to_frame(name='parent')\n",
    "eff_df = eff_series.to_frame(name='effect')\n",
    "med_df = med_series.to_frame(name='medical')\n",
    "neg_df = neg_series.to_frame(name='negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to reset index \n",
    "def reset_index(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('level_0', axis=1, inplace=True)\n",
    "    df.rename(columns={'level_1':'strain'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index on all dfs\n",
    "reset_index(flav_df)\n",
    "reset_index(par_df)\n",
    "reset_index(eff_df)\n",
    "reset_index(med_df)\n",
    "reset_index(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean/standardize all dfs \n",
    "\n",
    "#cat_df.reset_index('name', inplace=True)\n",
    "cat_df.rename(columns={'strain':'category'}, inplace=True)\n",
    "cat_df.rename(columns={'name':'strain'}, inplace=True)\n",
    "\n",
    "#remove $ from parents table\n",
    "par_df['strain'] = [x.strip('$') for x in par_df.strain]\n",
    "\n",
    "#make all entries lowercase\n",
    "flav_df = flav_df.apply(lambda x: x.astype(str).str.lower())\n",
    "par_df = par_df.apply(lambda x: x.astype(str).str.lower())\n",
    "eff_df = eff_df.apply(lambda x: x.astype(str).str.lower())\n",
    "med_df = med_df.apply(lambda x: x.astype(str).str.lower())\n",
    "neg_df = neg_df.apply(lambda x: x.astype(str).str.lower())\n",
    "cat_df = cat_df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "#replace - with space in all tables\n",
    "flav_df['strain'] = flav_df['strain'].str.replace('-',' ')\n",
    "par_df['strain'] = par_df['strain'].str.replace('-',' ')\n",
    "eff_df['strain'] = eff_df['strain'].str.replace('-',' ')\n",
    "med_df['strain'] = med_df['strain'].str.replace('-',' ')\n",
    "neg_df['strain'] = neg_df['strain'].str.replace('-',' ')\n",
    "cat_df['strain'] = cat_df['strain'].str.replace('-',' ')\n",
    "\n",
    "# Functions\n",
    "# #make all data lowercase\n",
    "# def lowercase(df):\n",
    "#     df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "#     return\n",
    "    \n",
    "# #replace dash with space in all tables\n",
    "# def replace_dash(df, column):\n",
    "#     df[column] = df[column].str.replace('-',' ')\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more cleaning/standardizing all dfs \n",
    "\n",
    "#function to remove [,], and ' characters\n",
    "def remove_char(df, column):\n",
    "    df[column] = df[column].str.replace('[',' ')\n",
    "    df[column] = df[column].str.replace(']',' ')\n",
    "    df[column] = df[column].str.replace(\"'\",'')\n",
    "    \n",
    "#function to split positive, medical and negative attributes\n",
    "#from being aggregated in 1 column to each their own column\n",
    "def new_columns_5(df, column):    \n",
    "    # new data frame with split value columns  \n",
    "    new1 = df[column].str.split(',', n = 1, expand = True)   \n",
    "    df[str(column) + '_1'] = new1[0] \n",
    "    df[str(column) + '_2'] = new1[1]\n",
    "\n",
    "    new2 = df[str(column) + '_2'].str.split(',', n = 1, expand = True)  \n",
    "    df[str(column) + '_2']= new2[0] \n",
    "    df[str(column) + '_3']= new2[1] \n",
    "  \n",
    "    new3 = df[str(column) + '_3'].str.split(',', n = 1, expand = True)\n",
    "    df[str(column) + '_3']= new3[0]\n",
    "    df[str(column) + '_4']= new3[1]\n",
    "\n",
    "    new4 = df[str(column) + '_4'].str.split(',', n = 1, expand = True)\n",
    "    df[str(column) + '_4']= new4[0]\n",
    "    df[str(column) + '_5']= new4[1]\n",
    "\n",
    "    #dropping old name columns \n",
    "    df.drop(columns =[column], inplace = True) \n",
    "\n",
    "#function to split flavor attributes from being aggregated in 1 column \n",
    "#to each their own column\n",
    "def new_columns_3(df, column):    \n",
    "    # new data frame with split value columns \n",
    "    new1 = df[column].str.split(',', n = 1, expand = True)   \n",
    "    df[str(column) + '_1'] = new1[0] \n",
    "    df[str(column) + '_2'] = new1[1]\n",
    "\n",
    "    new2 = df[str(column) + '_2'].str.split(',', n = 1, expand = True)  \n",
    "    df[str(column) + '_2']= new2[0] \n",
    "    df[str(column) + '_3']= new2[1] \n",
    "  \n",
    "    new3 = df[str(column) + '_3'].str.split(',', n = 1, expand = True)\n",
    "    df[str(column) + '_3']= new3[0]\n",
    "\n",
    "    #dropping old name columns \n",
    "    df.drop(columns =[column], inplace = True) \n",
    "    \n",
    "#function to split parent from being aggregated in 1 column \n",
    "#to each their own column\n",
    "def new_columns_2(df, column):    \n",
    "    \n",
    "    # new data frame with split value columns\n",
    "    new1 = df[column].str.split(',', n = 1, expand = True)   \n",
    "    df[str(column) + '_1'] = new1[0] \n",
    "    df[str(column) + '_2'] = new1[1]\n",
    "\n",
    "    #dropping old name columns \n",
    "    df.drop(columns =[column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying functions \n",
    "\n",
    "remove_char(flav_df, 'flavor')\n",
    "remove_char(par_df, 'parent')\n",
    "remove_char(eff_df, 'effect')\n",
    "remove_char(med_df, 'medical')\n",
    "remove_char(neg_df, 'negative')\n",
    "remove_char(cat_df, 'category')\n",
    "\n",
    "new_columns_5(eff_df, 'effect')\n",
    "new_columns_5(med_df, 'medical')\n",
    "new_columns_5(neg_df, 'negative')\n",
    "\n",
    "new_columns_3(flav_df, 'flavor')\n",
    "\n",
    "new_columns_2(par_df, 'parent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more cleanup\n",
    "par_df['strain'] = par_df['strain'].str.replace(\"'\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final cleaned and formatted dfs and csvs\n",
    "\n",
    "flav_final_df = pd.DataFrame(flav_df)\n",
    "flav_final_df.to_csv('flav_final_df.csv')\n",
    "\n",
    "par_final_df = pd.DataFrame(par_df)\n",
    "par_final_df.to_csv('par_final_df.csv')\n",
    "\n",
    "eff_final_df = pd.DataFrame(eff_df)\n",
    "eff_final_df.to_csv('eff_final_df.csv')\n",
    "\n",
    "med_final_df = pd.DataFrame(med_df)\n",
    "med_final_df.to_csv('med_final_df.csv')\n",
    "\n",
    "neg_final_df = pd.DataFrame(neg_df)\n",
    "neg_final_df.to_csv('neg_final_df.csv')\n",
    "\n",
    "cat_final_df = pd.DataFrame(cat_df)\n",
    "cat_final_df.to_csv('cat_final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final Merged Dataframe From Individual Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import final csvs\n",
    "\n",
    "flav_df = pd.read_csv('flav_final_df.csv')\n",
    "par_df = pd.read_csv('par_final_df.csv')\n",
    "eff_df = pd.read_csv('eff_final_df.csv')\n",
    "med_df = pd.read_csv('med_final_df.csv')\n",
    "neg_df = pd.read_csv('neg_final_df.csv')\n",
    "cat_df = pd.read_csv('cat_final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create master dataframe\n",
    "\n",
    "#drop unnecessary first column\n",
    "drop_column(flav_df)\n",
    "drop_column(par_df)\n",
    "drop_column(eff_df)\n",
    "drop_column(med_df)\n",
    "drop_column(neg_df)\n",
    "drop_column(cat_df)\n",
    "\n",
    "#merge df to create master df\n",
    "final_df = pd.merge(cat_df, eff_df, how='outer')\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "final_df = pd.merge(final_df, med_df, how='outer')\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "final_df = pd.merge(final_df, neg_df, how='outer')\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "final_df = pd.merge(final_df, flav_df, how='outer')\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "final_df = pd.merge(final_df, par_df, how='outer')\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "\n",
    "#final_df.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Using CountVectorizer and Cosine Similarity\n",
    "\n",
    "Some strains didn't have any values for Effects, Medical and Negative \n",
    "Attributes and I chose to remove those strains from the dataframe.\n",
    "I did this in pages and saved the csv as master_final_copy.\n",
    "\n",
    "I opted to drop the parent and review data, per my coaches instruction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('master_final_copy.csv')\n",
    "#master_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "master_df.fillna('none', inplace=True)\n",
    "\n",
    "#strip leading numbers from flavors columns\n",
    "master_df['flavor_1'] = master_df['flavor_1'].str.strip('1. ')\n",
    "master_df['flavor_2'] = master_df['flavor_2'].str.strip('2. ')\n",
    "master_df['flavor_3'] = master_df['flavor_3'].str.strip('3. ')\n",
    "\n",
    "\n",
    "to_drop = ['review_total', 'parent_1', 'parent_2', \n",
    "           'parent_3', 'parent_4', 'parent_5', \n",
    "           'parent_6', 'parent_7']\n",
    "\n",
    "master_df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df, column): \n",
    "    df[column] = df[column].str.replace('\"','')\n",
    "    df[column] = df[column].str.replace('#','')\n",
    "    df[column] = df[column].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(master_df, 'effect_1')\n",
    "clean(master_df, 'effect_2')\n",
    "clean(master_df, 'effect_3')\n",
    "clean(master_df, 'effect_4')\n",
    "clean(master_df, 'effect_5')\n",
    "clean(master_df, 'medical_1')\n",
    "clean(master_df, 'medical_2')\n",
    "clean(master_df, 'medical_3')\n",
    "clean(master_df, 'medical_4')\n",
    "clean(master_df, 'medical_5')\n",
    "clean(master_df, 'negative_1')\n",
    "clean(master_df, 'negative_2')\n",
    "clean(master_df, 'negative_3')\n",
    "clean(master_df, 'negative_4')\n",
    "clean(master_df, 'negative_5')\n",
    "clean(master_df, 'flavor_1')\n",
    "clean(master_df, 'flavor_2')\n",
    "clean(master_df, 'flavor_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>strain</th>\n",
       "      <th>effect_1</th>\n",
       "      <th>effect_2</th>\n",
       "      <th>effect_3</th>\n",
       "      <th>effect_4</th>\n",
       "      <th>effect_5</th>\n",
       "      <th>medical_1</th>\n",
       "      <th>medical_2</th>\n",
       "      <th>medical_3</th>\n",
       "      <th>medical_4</th>\n",
       "      <th>medical_5</th>\n",
       "      <th>negative_1</th>\n",
       "      <th>negative_2</th>\n",
       "      <th>negative_3</th>\n",
       "      <th>negative_4</th>\n",
       "      <th>negative_5</th>\n",
       "      <th>flavor_1</th>\n",
       "      <th>flavor_2</th>\n",
       "      <th>flavor_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, strain, effect_1, effect_2, effect_3, effect_4, effect_5, medical_1, medical_2, medical_3, medical_4, medical_5, negative_1, negative_2, negative_3, negative_4, negative_5, flavor_1, flavor_2, flavor_3]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for any duplicates\n",
    "ids = master_df['strain']\n",
    "master_df[ids.isin(ids[ids.duplicated()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization and Cosine Similarity\n",
    "\n",
    "I used Natural Language Processing (NLP) with scikit-learn’s CountVectorizer to convert attributes into vectors\n",
    "and then used scikit-learn’s cosine_similarity to build recommendation engine that takes in a strain and returns top 5 recommended strains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move category column to end\n",
    "df1 = master_df.pop('category')\n",
    "master_df['category'] = df1\n",
    "\n",
    "#combine all attributes into their own column to vectorize\n",
    "master_df['combined'] = master_df[master_df.columns[1:]].apply(lambda x: ', '.join(x), axis=1)\n",
    "\n",
    "#create final master for recs csv\n",
    "master_df.to_csv('master_for_recs.csv', index=False)\n",
    "\n",
    "#instantiating and generating the count matrix\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(master_df['combined'])\n",
    "\n",
    "#generating the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query and Get Recommendations Based on Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create colorgrid for recommendation table\n",
    "def color(x):\n",
    "    #effect colors:\n",
    "    if x == 'happy':\n",
    "        return 'background-color: #5F9F9F'\n",
    "    elif x == 'relaxed':\n",
    "        return 'background-color: #C0D9D9'\n",
    "    elif x == 'euphoric':\n",
    "        return 'background-color: #79CDCD'\n",
    "    elif x == 'uplifted':\n",
    "        return 'background-color: #66CCCC'\n",
    "    elif x == 'creative':\n",
    "        return 'background-color: #37FDFC'\n",
    "    elif x == 'energetic':\n",
    "        return 'background-color: #00CDCD'\n",
    "    elif x == 'focused':\n",
    "        return 'background-color: #39B7CD'\n",
    "    elif x == 'aroused':\n",
    "        return 'background-color: #9AC0CD'\n",
    "    elif x == 'sleepy':\n",
    "        return 'background-color: #0099CC'\n",
    "    elif x == 'hungry':\n",
    "        return 'background-color: #6996AD'\n",
    "    elif x == 'giggly':\n",
    "        return 'background-color: #87CEFF'\n",
    "    elif x == 'talkative':\n",
    "        return 'background-color: #74BBFB'\n",
    "\n",
    "    #medical colors:\n",
    "    elif x == 'stress':\n",
    "        return 'background-color: #458B00'\n",
    "    elif x == 'depression':\n",
    "        return 'background-color: #66CD00'\n",
    "    elif x == 'pain':\n",
    "        return 'background-color: #9CBA7F'\n",
    "    elif x == 'insomnia':\n",
    "        return 'background-color: #659D32'\n",
    "    elif x == 'fatigue':\n",
    "        return 'background-color: #BCED91'\n",
    "    elif x == 'headaches':\n",
    "        return 'background-color: #CFDBC5'\n",
    "    elif x == 'eyepressure':\n",
    "        return 'background-color: #567E3A'\n",
    "    elif x == 'lackofappetite':\n",
    "        return 'background-color: #84BE6A'\n",
    "    elif x == 'inflammation':\n",
    "        return 'background-color: #93DB70'\n",
    "    elif x == 'cramps':\n",
    "        return 'background-color: #86C67C'\n",
    "    elif x == 'musclespasms':\n",
    "        return 'background-color: #63AB62'  \n",
    "    elif x == 'nausea':\n",
    "        return 'background-color: #90EE90'\n",
    "    elif x == 'spasticity':\n",
    "        return 'background-color: #00CD00'\n",
    "    elif x == 'seizures':\n",
    "        return 'background-color: #F0FFF0'\n",
    "    \n",
    "    #negative colors:\n",
    "    elif x == 'drymouth':\n",
    "        return 'background-color: #EED2EE'\n",
    "    elif x == 'dryeyes':\n",
    "        return 'background-color: #DB70DB'\n",
    "    elif x == 'anxious':\n",
    "        return 'background-color: #CD00CD'  \n",
    "    elif x == 'dizzy':\n",
    "        return 'background-color: #FF00FF'\n",
    "    elif x == 'paranoid':\n",
    "        return 'background-color: #B5509C'\n",
    "    elif x == 'headache':\n",
    "        return 'background-color: #CDB5CD'\n",
    "    \n",
    "    #flavor colors:\n",
    "    elif x == 'earthy':\n",
    "        return 'background-color: #8B6508'\n",
    "    elif x == 'sweet':\n",
    "        return 'background-color: #ee918d'\n",
    "    elif x == 'citrus':\n",
    "        return 'background-color: #FFE700'\n",
    "    elif x == 'berry':\n",
    "        return 'background-color: #9b4466'\n",
    "    elif x == 'diesel':\n",
    "        return 'background-color: #696969'\n",
    "    elif x == 'lemon':\n",
    "        return 'background-color: #FFF44F'\n",
    "    elif x == 'pine':\n",
    "        return 'background-color: #01796f'\n",
    "    elif x == 'blueberry':\n",
    "        return 'background-color: #4f86f7'\n",
    "    elif x == 'flowery':\n",
    "        return 'background-color: #f4bfc7'\n",
    "    elif x == 'pungent':\n",
    "        return 'background-color: #808080'\n",
    "    elif x == 'woody':\n",
    "        return 'background-color: #554545'\n",
    "    elif x == 'grape':\n",
    "        return 'background-color: #6f2da8'\n",
    "    elif x == 'spicy/herbal':\n",
    "        return 'background-color: #FF0000'\n",
    "    elif x == 'skunk':\n",
    "        return 'background-color: #808080'\n",
    "    elif x == 'cheese':\n",
    "        return 'background-color: #FFF8DC'\n",
    "    elif x == 'tropical':\n",
    "        return 'background-color: #ff8aa1'\n",
    "    elif x == 'orange':\n",
    "        return 'background-color: #FFA500'\n",
    "    elif x == 'pineapple':\n",
    "        return 'background-color: #563c0d'\n",
    "    elif x == 'strawberry':\n",
    "        return 'background-color: #d53032'\n",
    "    elif x == 'apple':\n",
    "        return 'background-color: ##ff0800'\n",
    "    elif x == 'chemical':\n",
    "        return 'background-color: #778899'\n",
    "    elif x == 'mango':\n",
    "        return 'background-color: #ffcd48'\n",
    "    elif x == 'pepper':\n",
    "        return 'background-color: #2F4F4F'\n",
    "    elif x == 'lavender':\n",
    "        return 'background-color: #E6E6FA'\n",
    "    elif x == 'coffee':\n",
    "        return 'background-color: #6f4e37'\n",
    "    elif x == 'mint':\n",
    "        return 'background-color: #98ff98'\n",
    "    elif x == 'honey':\n",
    "        return 'background-color: #a98307'\n",
    "    elif x == 'lime':\n",
    "        return 'background-color: #00FF00'\n",
    "    elif x == 'grapefruit':\n",
    "        return 'background-color: #edadaa'\n",
    "    elif x == 'vanilla':\n",
    "        return 'background-color: #f3e5ab'\n",
    "    elif x == 'sage':\n",
    "        return 'background-color: #77815c'\n",
    "    elif x == 'butter':\n",
    "        return 'background-color: #fdf6c5'\n",
    "    elif x == 'nutty':\n",
    "        return 'background-color: #cd9141'\n",
    "    elif x == 'bluecheese':\n",
    "        return 'background-color: #87CEEB'\n",
    "    elif x == 'tobacco':\n",
    "        return 'background-color: #6d5843'\n",
    "    elif x == 'plum':\n",
    "        return 'background-color: #DDA0DD'\n",
    "    elif x == 'pear':\n",
    "        return 'background-color: #d1e231'\n",
    "    elif x == 'violet':\n",
    "        return 'background-color: #9400D3'\n",
    "    elif x == 'tar':\n",
    "        return 'background-color: #383838'\n",
    "    elif x == 'menthol':\n",
    "        return 'background-color: #c1f9a2 '\n",
    "    elif x == 'ammonia':\n",
    "        return 'background-color: #FFFF33'\n",
    "    elif x == 'rose':\n",
    "        return 'background-color: #ff007f '\n",
    "    elif x == 'tea':\n",
    "        return 'background-color: #832400'\n",
    "    elif x == 'peach':\n",
    "        return 'background-color: #ffe5b4'\n",
    "    elif x == 'apricot':\n",
    "        return 'background-color: #fbceb1'\n",
    "    elif x == 'chestnut':\n",
    "        return 'background-color: #954535'\n",
    "    elif x == 'treefruit':\n",
    "        return 'background-color: #8db600'\n",
    "       \n",
    "    #type colors:     \n",
    "    elif x == 'sativa':\n",
    "        return 'background-color: #cc5500'\n",
    "    elif x == 'indica':\n",
    "        return 'background-color: #800080'\n",
    "    elif x == 'hybrid':\n",
    "        return 'background-color: #758b72'\n",
    "    \n",
    "    #none and strain colors:xz\n",
    "    elif x == 'none':\n",
    "        return 'background-color: black'\n",
    "    else:\n",
    "        return 'background-color: white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cherry skunk', 'elvis', 'blueberry headband', 'white berry', 'bruce banner 3']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col1 {\n",
       "            background-color:  #5F9F9F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col2 {\n",
       "            background-color:  #C0D9D9;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col3 {\n",
       "            background-color:  #79CDCD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col4 {\n",
       "            background-color:  #66CCCC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col5 {\n",
       "            background-color:  #37FDFC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col6 {\n",
       "            background-color:  #458B00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col7 {\n",
       "            background-color:  #66CD00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col8 {\n",
       "            background-color:  #9CBA7F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col9 {\n",
       "            background-color:  #CFDBC5;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col10 {\n",
       "            background-color:  #BCED91;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col11 {\n",
       "            background-color:  #EED2EE;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col12 {\n",
       "            background-color:  #DB70DB;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col13 {\n",
       "            background-color:  #CD00CD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col14 {\n",
       "            background-color:  #FF00FF;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col15 {\n",
       "            background-color:  #B5509C;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col16 {\n",
       "            background-color:  #4f86f7;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col17 {\n",
       "            background-color:  #ee918d;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col18 {\n",
       "            background-color:  #9b4466;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col19 {\n",
       "            background-color:  #758b72;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col1 {\n",
       "            background-color:  #5F9F9F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col2 {\n",
       "            background-color:  #C0D9D9;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col3 {\n",
       "            background-color:  #79CDCD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col4 {\n",
       "            background-color:  #37FDFC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col5 {\n",
       "            background-color:  #66CCCC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col6 {\n",
       "            background-color:  #9CBA7F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col7 {\n",
       "            background-color:  #458B00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col8 {\n",
       "            background-color:  #66CD00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col9 {\n",
       "            background-color:  #BCED91;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col10 {\n",
       "            background-color:  #CFDBC5;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col11 {\n",
       "            background-color:  #EED2EE;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col12 {\n",
       "            background-color:  #DB70DB;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col13 {\n",
       "            background-color:  #FF00FF;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col14 {\n",
       "            background-color:  #CD00CD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col15 {\n",
       "            background-color:  #B5509C;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col16 {\n",
       "            background-color:  #ee918d;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col17 {\n",
       "            background-color:  #9b4466;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col18 {\n",
       "            background-color:  #8B6508;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col19 {\n",
       "            background-color:  #758b72;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col1 {\n",
       "            background-color:  #66CCCC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col2 {\n",
       "            background-color:  #C0D9D9;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col3 {\n",
       "            background-color:  #79CDCD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col4 {\n",
       "            background-color:  #5F9F9F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col5 {\n",
       "            background-color:  #37FDFC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col6 {\n",
       "            background-color:  #458B00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col7 {\n",
       "            background-color:  #9CBA7F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col8 {\n",
       "            background-color:  #66CD00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col9 {\n",
       "            background-color:  #BCED91;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col10 {\n",
       "            background-color:  #CFDBC5;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col11 {\n",
       "            background-color:  #CD00CD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col12 {\n",
       "            background-color:  #FF00FF;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col13 {\n",
       "            background-color:  #EED2EE;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col14 {\n",
       "            background-color:  #B5509C;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col15 {\n",
       "            background-color:  #DB70DB;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col16 {\n",
       "            background-color:  #808080;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col17 {\n",
       "            background-color:  #ee918d;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col18 {\n",
       "            background-color:  #8B6508;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col19 {\n",
       "            background-color:  #758b72;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col1 {\n",
       "            background-color:  #C0D9D9;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col2 {\n",
       "            background-color:  #5F9F9F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col3 {\n",
       "            background-color:  #79CDCD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col4 {\n",
       "            background-color:  #66CCCC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col5 {\n",
       "            background-color:  #00CDCD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col6 {\n",
       "            background-color:  #458B00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col7 {\n",
       "            background-color:  #9CBA7F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col8 {\n",
       "            background-color:  #66CD00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col9 {\n",
       "            background-color:  #84BE6A;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col10 {\n",
       "            background-color:  #CFDBC5;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col11 {\n",
       "            background-color:  #EED2EE;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col12 {\n",
       "            background-color:  #DB70DB;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col13 {\n",
       "            background-color:  #FF00FF;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col14 {\n",
       "            background-color:  #CD00CD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col15 {\n",
       "            background-color:  #CDB5CD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col16 {\n",
       "            background-color:  #4f86f7;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col17 {\n",
       "            background-color:  #ee918d;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col18 {\n",
       "            background-color:  #9b4466;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col19 {\n",
       "            background-color:  #758b72;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col1 {\n",
       "            background-color:  #C0D9D9;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col2 {\n",
       "            background-color:  #5F9F9F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col3 {\n",
       "            background-color:  #0099CC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col4 {\n",
       "            background-color:  #37FDFC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col5 {\n",
       "            background-color:  #79CDCD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col6 {\n",
       "            background-color:  #458B00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col7 {\n",
       "            background-color:  #9CBA7F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col8 {\n",
       "            background-color:  #66CD00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col9 {\n",
       "            background-color:  #84BE6A;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col10 {\n",
       "            background-color:  #BCED91;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col11 {\n",
       "            background-color:  #EED2EE;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col12 {\n",
       "            background-color:  #DB70DB;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col13 {\n",
       "            background-color:  #FF00FF;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col14 {\n",
       "            background-color:  #B5509C;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col15 {\n",
       "            background-color:  #CD00CD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col16 {\n",
       "            background-color:  #9b4466;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col17 {\n",
       "            background-color:  #ee918d;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col18 {\n",
       "            background-color:  #4f86f7;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col19 {\n",
       "            background-color:  #800080;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col1 {\n",
       "            background-color:  #5F9F9F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col2 {\n",
       "            background-color:  #C0D9D9;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col3 {\n",
       "            background-color:  #79CDCD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col4 {\n",
       "            background-color:  #37FDFC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col5 {\n",
       "            background-color:  #66CCCC;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col6 {\n",
       "            background-color:  #458B00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col7 {\n",
       "            background-color:  #66CD00;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col8 {\n",
       "            background-color:  #9CBA7F;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col9 {\n",
       "            background-color:  #BCED91;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col10 {\n",
       "            background-color:  #86C67C;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col11 {\n",
       "            background-color:  #EED2EE;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col12 {\n",
       "            background-color:  #DB70DB;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col13 {\n",
       "            background-color:  #CD00CD;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col14 {\n",
       "            background-color:  #FF00FF;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col15 {\n",
       "            background-color:  #B5509C;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col16 {\n",
       "            background-color:  #ee918d;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col17 {\n",
       "            background-color:  #696969;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col18 {\n",
       "            background-color:  #8B6508;\n",
       "        }    #T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col19 {\n",
       "            background-color:  #758b72;\n",
       "        }</style><table id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >strain</th>        <th class=\"col_heading level0 col1\" >effect_1</th>        <th class=\"col_heading level0 col2\" >effect_2</th>        <th class=\"col_heading level0 col3\" >effect_3</th>        <th class=\"col_heading level0 col4\" >effect_4</th>        <th class=\"col_heading level0 col5\" >effect_5</th>        <th class=\"col_heading level0 col6\" >medical_1</th>        <th class=\"col_heading level0 col7\" >medical_2</th>        <th class=\"col_heading level0 col8\" >medical_3</th>        <th class=\"col_heading level0 col9\" >medical_4</th>        <th class=\"col_heading level0 col10\" >medical_5</th>        <th class=\"col_heading level0 col11\" >negative_1</th>        <th class=\"col_heading level0 col12\" >negative_2</th>        <th class=\"col_heading level0 col13\" >negative_3</th>        <th class=\"col_heading level0 col14\" >negative_4</th>        <th class=\"col_heading level0 col15\" >negative_5</th>        <th class=\"col_heading level0 col16\" >flavor_1</th>        <th class=\"col_heading level0 col17\" >flavor_2</th>        <th class=\"col_heading level0 col18\" >flavor_3</th>        <th class=\"col_heading level0 col19\" >category</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460flevel0_row0\" class=\"row_heading level0 row0\" >309</th>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col0\" class=\"data row0 col0\" >blue dream</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col1\" class=\"data row0 col1\" >happy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col2\" class=\"data row0 col2\" >relaxed</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col3\" class=\"data row0 col3\" >euphoric</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col4\" class=\"data row0 col4\" >uplifted</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col5\" class=\"data row0 col5\" >creative</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col6\" class=\"data row0 col6\" >stress</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col7\" class=\"data row0 col7\" >depression</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col8\" class=\"data row0 col8\" >pain</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col9\" class=\"data row0 col9\" >headaches</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col10\" class=\"data row0 col10\" >fatigue</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col11\" class=\"data row0 col11\" >drymouth</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col12\" class=\"data row0 col12\" >dryeyes</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col13\" class=\"data row0 col13\" >anxious</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col14\" class=\"data row0 col14\" >dizzy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col15\" class=\"data row0 col15\" >paranoid</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col16\" class=\"data row0 col16\" >blueberry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col17\" class=\"data row0 col17\" >sweet</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col18\" class=\"data row0 col18\" >berry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow0_col19\" class=\"data row0 col19\" >hybrid</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460flevel0_row1\" class=\"row_heading level0 row1\" >563</th>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col0\" class=\"data row1 col0\" >cherry skunk</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col1\" class=\"data row1 col1\" >happy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col2\" class=\"data row1 col2\" >relaxed</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col3\" class=\"data row1 col3\" >euphoric</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col4\" class=\"data row1 col4\" >creative</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col5\" class=\"data row1 col5\" >uplifted</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col6\" class=\"data row1 col6\" >pain</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col7\" class=\"data row1 col7\" >stress</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col8\" class=\"data row1 col8\" >depression</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col9\" class=\"data row1 col9\" >fatigue</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col10\" class=\"data row1 col10\" >headaches</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col11\" class=\"data row1 col11\" >drymouth</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col12\" class=\"data row1 col12\" >dryeyes</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col13\" class=\"data row1 col13\" >dizzy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col14\" class=\"data row1 col14\" >anxious</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col15\" class=\"data row1 col15\" >paranoid</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col16\" class=\"data row1 col16\" >sweet</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col17\" class=\"data row1 col17\" >berry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col18\" class=\"data row1 col18\" >earthy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow1_col19\" class=\"data row1 col19\" >hybrid</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460flevel0_row2\" class=\"row_heading level0 row2\" >848</th>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col0\" class=\"data row2 col0\" >elvis</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col1\" class=\"data row2 col1\" >uplifted</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col2\" class=\"data row2 col2\" >relaxed</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col3\" class=\"data row2 col3\" >euphoric</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col4\" class=\"data row2 col4\" >happy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col5\" class=\"data row2 col5\" >creative</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col6\" class=\"data row2 col6\" >stress</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col7\" class=\"data row2 col7\" >pain</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col8\" class=\"data row2 col8\" >depression</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col9\" class=\"data row2 col9\" >fatigue</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col10\" class=\"data row2 col10\" >headaches</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col11\" class=\"data row2 col11\" >anxious</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col12\" class=\"data row2 col12\" >dizzy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col13\" class=\"data row2 col13\" >drymouth</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col14\" class=\"data row2 col14\" >paranoid</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col15\" class=\"data row2 col15\" >dryeyes</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col16\" class=\"data row2 col16\" >skunk</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col17\" class=\"data row2 col17\" >sweet</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col18\" class=\"data row2 col18\" >earthy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow2_col19\" class=\"data row2 col19\" >hybrid</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460flevel0_row3\" class=\"row_heading level0 row3\" >370</th>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col0\" class=\"data row3 col0\" >blueberry headband</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col1\" class=\"data row3 col1\" >relaxed</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col2\" class=\"data row3 col2\" >happy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col3\" class=\"data row3 col3\" >euphoric</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col4\" class=\"data row3 col4\" >uplifted</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col5\" class=\"data row3 col5\" >energetic</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col6\" class=\"data row3 col6\" >stress</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col7\" class=\"data row3 col7\" >pain</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col8\" class=\"data row3 col8\" >depression</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col9\" class=\"data row3 col9\" >lackofappetite</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col10\" class=\"data row3 col10\" >headaches</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col11\" class=\"data row3 col11\" >drymouth</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col12\" class=\"data row3 col12\" >dryeyes</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col13\" class=\"data row3 col13\" >dizzy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col14\" class=\"data row3 col14\" >anxious</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col15\" class=\"data row3 col15\" >headache</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col16\" class=\"data row3 col16\" >blueberry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col17\" class=\"data row3 col17\" >sweet</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col18\" class=\"data row3 col18\" >berry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow3_col19\" class=\"data row3 col19\" >hybrid</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460flevel0_row4\" class=\"row_heading level0 row4\" >2523</th>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col0\" class=\"data row4 col0\" >white berry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col1\" class=\"data row4 col1\" >relaxed</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col2\" class=\"data row4 col2\" >happy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col3\" class=\"data row4 col3\" >sleepy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col4\" class=\"data row4 col4\" >creative</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col5\" class=\"data row4 col5\" >euphoric</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col6\" class=\"data row4 col6\" >stress</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col7\" class=\"data row4 col7\" >pain</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col8\" class=\"data row4 col8\" >depression</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col9\" class=\"data row4 col9\" >lackofappetite</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col10\" class=\"data row4 col10\" >fatigue</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col11\" class=\"data row4 col11\" >drymouth</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col12\" class=\"data row4 col12\" >dryeyes</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col13\" class=\"data row4 col13\" >dizzy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col14\" class=\"data row4 col14\" >paranoid</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col15\" class=\"data row4 col15\" >anxious</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col16\" class=\"data row4 col16\" >berry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col17\" class=\"data row4 col17\" >sweet</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col18\" class=\"data row4 col18\" >blueberry</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow4_col19\" class=\"data row4 col19\" >indica</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460flevel0_row5\" class=\"row_heading level0 row5\" >419</th>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col0\" class=\"data row5 col0\" >bruce banner 3</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col1\" class=\"data row5 col1\" >happy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col2\" class=\"data row5 col2\" >relaxed</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col3\" class=\"data row5 col3\" >euphoric</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col4\" class=\"data row5 col4\" >creative</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col5\" class=\"data row5 col5\" >uplifted</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col6\" class=\"data row5 col6\" >stress</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col7\" class=\"data row5 col7\" >depression</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col8\" class=\"data row5 col8\" >pain</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col9\" class=\"data row5 col9\" >fatigue</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col10\" class=\"data row5 col10\" >cramps</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col11\" class=\"data row5 col11\" >drymouth</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col12\" class=\"data row5 col12\" >dryeyes</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col13\" class=\"data row5 col13\" >anxious</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col14\" class=\"data row5 col14\" >dizzy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col15\" class=\"data row5 col15\" >paranoid</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col16\" class=\"data row5 col16\" >sweet</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col17\" class=\"data row5 col17\" >diesel</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col18\" class=\"data row5 col18\" >earthy</td>\n",
       "                        <td id=\"T_f07762a0_c8ef_11e9_9ac5_38f9d33c460frow5_col19\" class=\"data row5 col19\" >hybrid</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a1e3bec88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a Series for the strains so they are associated to an ordered numerical\n",
    "#list I will use in the function to match the indexes\n",
    "#indices = pd.Series(master_df.index)\n",
    "\n",
    "#defining the function that takes in strain \n",
    "#as input and returns the top 5 recommended strains\n",
    "def recommended_strains(strain, cosine_sim = cosine_sim):\n",
    "    \n",
    "    # initializing the empty list of recommended strains\n",
    "    recommended_strain_index = []\n",
    "    \n",
    "    # gettin the index of the strain that matches the strain\n",
    "    idx = master_df[master_df['strain']==strain].index[0]\n",
    "    \n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 5 most similar strains\n",
    "    top_5_indexes = list(score_series.iloc[1:6].index)\n",
    "    \n",
    "    # populating the list with the titles of the best 5 matching strains\n",
    "    for i in top_5_indexes:\n",
    "        recommended_strain_index.append(list(master_df.index)[i])\n",
    "        #recommended_strains.append((unedited_df.ix[i]['strain']))\n",
    "        #unedited_df.ix[id]['strain']\n",
    "    #return recommended_strains\n",
    "\n",
    "    recommended_strains = []\n",
    "    \n",
    "    for i in recommended_strain_index:\n",
    "        recommended_strain = master_df.ix[i]['strain']\n",
    "        recommended_strains.append(recommended_strain)\n",
    "    \n",
    "    return recommended_strains\n",
    "\n",
    "print(recommended_strains('blue dream'))\n",
    "\n",
    "# build table with inputted strain and 5 most similar\n",
    "\n",
    "def build_comp_table_vec(df, strain):    \n",
    "    strain_0 = df[df['strain'] == strain]\n",
    "    strain_1 = df[df['strain'] == recommended_strains(strain)[0]]\n",
    "    strain_2 = df[df['strain'] == recommended_strains(strain)[1]]\n",
    "    strain_3 = df[df['strain'] == recommended_strains(strain)[2]]\n",
    "    strain_4 = df[df['strain'] == recommended_strains(strain)[3]]\n",
    "    strain_5 = df[df['strain'] == recommended_strains(strain)[4]]\n",
    "    \n",
    "    to_append = [strain_1, strain_2, strain_3, strain_4, strain_5]\n",
    "    table = strain_0.append(to_append)\n",
    "\n",
    "    return table\n",
    "\n",
    "top_matches = build_comp_table_vec(master_df, 'blue dream')\n",
    "top_matches = top_matches.iloc[:, :-1]\n",
    "top_matches.style.applymap(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Data Retrieval\n",
    "\n",
    "When scraping for parental lineage, I missed some parents. I needed to rescrape \n",
    "to get the additional information and in the process my ip got blocked.\n",
    "I moved to working in smaller scrape batches. I then needed to append each of my smaller\n",
    "batches into a master table.\n",
    "\n",
    "(Since I was going to be scraping again, I also decided to scrape for the review counts.)\n",
    "\n",
    "I didn't even end up using any of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv('urls.csv')\n",
    "urls_list = urls['url']\n",
    "\n",
    "urls_to_156 = urls_list[:156]                    #parents1.csv\n",
    "urls_156_to_312 = urls_list[156:312]             #parents2.csv\n",
    "urls_312_to_468 = urls_list[312:468]             #parents3.csv\n",
    "urls_468_to_624 = urls_list[468:624]             #parents4.csv\n",
    "urls_624_to_780 = urls_list[624:780]             #parents5.csv\n",
    "urls_780_to_936 = urls_list[780:936]             #parents6.csv\n",
    "urls_936_to_1092 = urls_list[936:1092]           #parents7.csv\n",
    "urls_1092_to_1248 = urls_list[1092:1248]         #parents8.csv\n",
    "urls_1248_to_1404 = urls_list[1248:1404]         #parents9.csv\n",
    "urls_1404_to_1560 = urls_list[1404:1560]         #parents10.csv\n",
    "urls_1560_to_2060 = urls_list[1560:2060]         #parents11.csv\n",
    "urls_2060_to_2560 = urls_list[2060:2560]         #parents12.csv\n",
    "urls_2560_to_3060 = urls_list[2560:3060]         #parents13.csv\n",
    "urls_3060_to_end = urls_list[3060:]              #parents14.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape for review totals and parents\n",
    "\n",
    "parents = []\n",
    "reviews = []\n",
    "\n",
    "for url in tqdm(urls_list):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    try:\n",
    "        container = soup.find(\"a\",{\"class\":\"active\"})  \n",
    "        strain_name = container.get('href') \n",
    "        strain = strain_name.split('/')\n",
    "    except:\n",
    "        None\n",
    "    \n",
    "    try:\n",
    "        parent = soup.findAll('div',attrs={\"class\" : \"strain-tile-footer\"})\n",
    "        parents.append(parent)\n",
    "    except:\n",
    "        parents.append(strain[2], None)\n",
    "    \n",
    "    try:\n",
    "        container = soup.find(\"a\",{\"class\":\"active\"})  \n",
    "        strain_name = container.get('href') \n",
    "        strain = strain_name.split('/')\n",
    "        review_total = soup.find('a',attrs={\"onclick\" : \"window.strainHelpers.trackEvent('User Interactions', 'Strain Details', 'View all Reviews')\"}).text\n",
    "        review = review_total[review_total.find(\"(\")+1:review_total.find(\")\")]\n",
    "        rev_name = [strain[2], review]\n",
    "    except:\n",
    "        rev_name = [strain[2], None]\n",
    "    \n",
    "    reviews.append(rev_name)\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape for parents\n",
    "#change variable in 6 places for each small batch\n",
    "\n",
    "parents14_ = []\n",
    "\n",
    "for url in tqdm(urls_3060_to_end):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    try:\n",
    "\n",
    "        children = soup.findAll('div',attrs={\"class\" : \"strain-tile-footer\"})\n",
    "        parents14_.append(children)\n",
    "    \n",
    "    except:\n",
    "        None\n",
    "\n",
    "    time.sleep(2)        \n",
    " \n",
    "parents14 = pd.DataFrame(parents14_)\n",
    "parents14.to_csv('parents14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create review df and save to csv\n",
    "review_totals = pd.DataFrame(reviews)\n",
    "review_totals.to_csv('review_totals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create parent df and save to csv\n",
    "parents_final = pd.DataFrame(parents)\n",
    "parents_final.to_csv('parents_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minor cleanup\n",
    "review_totals.rename(columns=({0:'strain', 1:'review_total'}), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved as csv and reread them in to notebook\n",
    "review_totals.to_csv('review_totals.csv')\n",
    "parents_final.to_csv('parents_final.csv')\n",
    "\n",
    "review_totals = pd.read_csv('review_totals.csv')\n",
    "parents_final = pd.read_csv('parents_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renamed to total_reviews \n",
    "total_reviews = pd.read_csv('review_totals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minor cleanup\n",
    "total_reviews.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "total_reviews.drop('Unnamed: 0.1', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minor cleanup\n",
    "total_reviews['strain'] = total_reviews['strain'].str.replace('-',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "total_reviews.to_csv('total_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = pd.read_csv('parents_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csvs created from scraping in smaller batches\n",
    "#need to append these into master table\n",
    "parent1a = pd.read_csv('parents1.csv')\n",
    "parent2a = pd.read_csv('parents2.csv')\n",
    "parent3a = pd.read_csv('parents3.csv')\n",
    "parent4a = pd.read_csv('parents4.csv')\n",
    "parent5a = pd.read_csv('parents5.csv')\n",
    "parent6a = pd.read_csv('parents6.csv')\n",
    "parent7a = pd.read_csv('parents7.csv')\n",
    "parent8a = pd.read_csv('parents8.csv')\n",
    "parent9a = pd.read_csv('parents9.csv')\n",
    "parent10a = pd.read_csv('parents10.csv')\n",
    "parent11a = pd.read_csv('parents11.csv')\n",
    "parent12a = pd.read_csv('parents12.csv')\n",
    "parent13a = pd.read_csv('parents13.csv')\n",
    "parent14a = pd.read_csv('parents14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent list to append to master dataframe\n",
    "append_list = [parent2a, parent3a, parent4a, parent5a, parent6a, parent7a,\n",
    "              parent8a, parent9a, parent10a, parent11a, parent12a, parent13a,\n",
    "              parent14a]             \n",
    "\n",
    "#create master parent df\n",
    "master_df = parent1a.append(append_list, ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "# master_df.to_csv('master_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in master parent df\n",
    "master_df = pd.read_csv('master_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract parent strain name from html\n",
    "def split_string(string):\n",
    "    try:\n",
    "        return re.findall('<div class=\"strain-tile-footer\">(.+)</div>', string)\n",
    "    except:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean each column in df\n",
    "master_df['1'] = master_df['0'].apply(split_string)\n",
    "master_df.replace('N, o, n, e', 'n')\n",
    "master_df['1'] = master_df['1'].apply(', '.join)\n",
    "master_df['1'] = [x.strip('$') for x in master_df['1']]\n",
    "master_df['1'] = master_df['1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_values(df, column):\n",
    "    df[column] = df[column].apply(split_string)\n",
    "    df[column] = df[column].apply(', '.join)\n",
    "    df[column] = [x.strip('$') for x in df[column]]\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].str.replace(\"'\",'')\n",
    "    df[column] = df[column].str.replace(\".\",'')\n",
    "    df[column] = df[column].str.replace(\"#\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format_values(master_df, '0')\n",
    "# format_values(master_df, '1')\n",
    "# format_values(master_df, '2')\n",
    "# format_values(master_df, '3')\n",
    "# format_values(master_df, '4')\n",
    "# format_values(master_df, '5')\n",
    "# format_values(master_df, '6')\n",
    " format_values(master_df, '7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "master_df.rename(columns={'0': 'strain', '1':'parent_1', '2':'parent_2',\n",
    "                         '3':'parent_3', '4':'parent_4', '5':'parent_5',\n",
    "                         '6':'parent_6', '7':'parent_7'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary column\n",
    "master_df.drop('Unnamed: 0.1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "# master_df.to_csv('master_parent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge total_reviews table to finals df\n",
    "final_df = pd.merge(final_df, total_reviews, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "final_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates from table\n",
    "final_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final df to csv\n",
    "# final_df.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in final df\n",
    "final_df = pd.read_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "final_df.drop('parent_1', axis=1, inplace=True)\n",
    "final_df.drop('parent_2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in master parent df to merge with final df\n",
    "master_parent = pd.read_csv('master_parent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge master parent df to finals df\n",
    "final_df = pd.merge(final_df, master_parent, on='strain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns and duplicates\n",
    "final_df.drop('Unnamed: 0_y', axis=1, inplace=True)\n",
    "final_df.drop('Unnamed: 0_x', axis=1, inplace=True)\n",
    "final_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final df to csv\n",
    "# final_df.to_csv('master_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
